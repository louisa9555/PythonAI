{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba15d722",
   "metadata": {},
   "source": [
    "# EP 3: Machine Learning 101\n",
    "\n",
    "üìö ‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤(Fastwork): <a href=\"https://fastwork.co/user/krittachailouis/tutoring-12693427\">https://fastwork.co/user/krittachailouis/tutoring-12693427</a>\n",
    "\n",
    "<img width=\"32\" alt=\"YouTube icon\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/YouTube_full-color_icon_%282017%29.svg/32px-YouTube_full-color_icon_%282017%29.svg.png?20240107144800\"> Youtube:\n",
    " <a href=\"https://commons.wikimedia.org/wiki/File:YouTube_full-color_icon_(2017).svg\">\n",
    "  Louis MakerLab\n",
    " </a>\n",
    " \n",
    "<img width=\"32\" alt=\"GitHub icon\" src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"> GitHub: \n",
    "<a href=\"https://github.com/louisa9555\">\n",
    "  Louis MakerLab\n",
    "</a>\n",
    "\n",
    "\n",
    "## Linear Models, Tree-based Models ‡πÅ‡∏•‡∏∞ Kernel Methods\n",
    "### ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÉ‡∏ô‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏ô‡∏µ‡πâ:\n",
    "1. **Linear Models (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô)**\n",
    "   - Linear Regression (‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô)\n",
    "   - Logistic Regression (‡∏Å‡∏≤‡∏£‡∏ñ‡∏î‡∏ñ‡∏≠‡∏¢‡πÇ‡∏•‡∏à‡∏¥‡∏™‡∏ï‡∏¥‡∏Å)\n",
    "2. **Tree-based Models (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ)**\n",
    "   - Decision Trees (‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à)\n",
    "   - Random Forests (‡∏õ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°)\n",
    "   - XGBoost\n",
    "3. **Kernel Methods (‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏Ñ‡∏≠‡∏£‡πå‡πÄ‡∏ô‡∏•)**\n",
    "   - Support Vector Machine (SVM)\n",
    "   - Gaussian Processes\n",
    "\n",
    "---\n",
    "\n",
    "### ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏ô‡∏£‡∏π‡πâ:\n",
    "- ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î\n",
    "- ‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡πâ‡∏î Python ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏•\n",
    "- ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d23a1",
   "metadata": {},
   "source": [
    "## ‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á\n",
    "- ‡∏™‡∏£‡πâ‡∏≤‡∏á conda env\n",
    "- `conda install -c conda-forge llvm-openmp`\n",
    "- `brew install libomp`\n",
    "- pip install numpy pandas matplotlib seaborn scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325a0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification, make_regression, load_iris, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, classification_report, confusion_matrix\n",
    "\n",
    "# Linear Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "# Tree-based Models\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Kernel Methods\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier, GaussianProcessRegressor\n",
    "\n",
    "# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ matplotlib ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\n",
    "import matplotlib.font_manager as fm\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!\")\n",
    "\n",
    "# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢‡πÉ‡∏ô matplotlib\n",
    "def setup_matplotlib_thai_font():\n",
    "    \"\"\"Find and return a Thai font if available\"\"\"\n",
    "    # Candidate font names that support Thai\n",
    "    thai_fonts = [\"TH Sarabun New\", \"Noto Sans Thai\", \"Noto Serif Thai\", \"Tahoma\", \"Angsana New\"]\n",
    "\n",
    "    # Get list of installed fonts\n",
    "    font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "    for font_path in font_list:\n",
    "        prop = fm.FontProperties(fname=font_path)\n",
    "        try:\n",
    "            name = prop.get_name()\n",
    "            if any(tf in name for tf in thai_fonts):\n",
    "                print(f\"‚úî Using Thai font: {name}\")\n",
    "                return prop\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(\"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÑ‡∏ó‡∏¢, ‡πÉ‡∏ä‡πâ‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô.\")\n",
    "    return None\n",
    "\n",
    "# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå matplotlib\n",
    "matplotlib_thai_font = setup_matplotlib_thai_font()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf056005",
   "metadata": {},
   "source": [
    "## ‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2: Tree-based Models (‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ)\n",
    "\n",
    "### 2.1 Decision Trees (‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à)\n",
    "\n",
    "**‡∏ó‡∏§‡∏©‡∏é‡∏µ:**\n",
    "- Decision Trees ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\n",
    "- ‡πÅ‡∏ï‡πà‡∏•‡∏∞ node ‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "- ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡πÄ‡∏ä‡πà‡∏ô Gini Impurity ‡∏´‡∏£‡∏∑‡∏≠ Information Gain ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏ö‡πà‡∏á\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á:**\n",
    "- ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢\n",
    "- ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö scaling ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö features ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÑ‡∏î‡πâ\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô:**\n",
    "- ‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡πÇ‡∏ô‡πâ‡∏° overfitting\n",
    "- ‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢‡∏≠‡∏≤‡∏à‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏°‡∏≤‡∏Å)\n",
    "- ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4432cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Iris dataset ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Decision Tree\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X_iris, y_iris = iris.data, iris.target\n",
    "print(X_iris.shape)\n",
    "print(\"(0 = Setosa, 1 = Versicolor, 2 = Virginica)\")\n",
    "print(y_iris)\n",
    "# plot ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô\n",
    "df_iris = pd.DataFrame(X_iris, columns=iris.feature_names)\n",
    "df_iris['target'] = y_iris\n",
    "df_iris['target'] = df_iris['target'].map({0: 'Setosa', 1: 'Versicolor', 2: 'Virginica'})\n",
    "display(df_iris.head())\n",
    "if matplotlib_thai_font:\n",
    "\tplt.rcParams['font.family'] = matplotlib_thai_font.get_name()\n",
    "sns.pairplot(df_iris, hue='target', diag_kind='kde')\n",
    "plt.suptitle('‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Iris Dataset', y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db0d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•\n",
    "X_train_tree, X_test_tree, y_train_tree, y_test_tree = train_test_split(\n",
    "    X_iris, y_iris, test_size=0.3\n",
    ")\n",
    "\n",
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Decision Tree\n",
    "dt_classifier = DecisionTreeClassifier(max_depth=3)\n",
    "dt_classifier.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
    "y_pred_tree = dt_classifier.predict(X_test_tree)\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "accuracy_tree = accuracy_score(y_test_tree, y_pred_tree)\n",
    "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á Decision Tree: {accuracy_tree:.3f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Feature Importance\n",
    "feature_importance = dt_classifier.feature_importances_\n",
    "print(\"\\nFeature Importance:\", feature_importance)\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "print(\"\\n‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ç‡∏≠‡∏á Features:\")\n",
    "for i, (name, importance) in enumerate(zip(feature_names, feature_importance)):\n",
    "    print(f\"{name}: {importance:.3f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏£‡∏≤‡∏ü Feature Importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importance)), feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('Feature Importance ‡πÉ‡∏ô Decision Tree')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm_tree = confusion_matrix(y_test_tree, y_pred_tree)\n",
    "sns.heatmap(cm_tree, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "plt.title('Confusion Matrix - Decision Tree')\n",
    "plt.xlabel('‡∏Ñ‡πà‡∏≤‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢')\n",
    "plt.ylabel('‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df564d89",
   "metadata": {},
   "source": [
    "### 2.2 Random Forests (‡∏õ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°, Ensemble learning technique)\n",
    "\n",
    "**‡∏ó‡∏§‡∏©‡∏é‡∏µ:**\n",
    "- Random Forest ‡πÄ‡∏õ‡πá‡∏ô ensemble method ‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏° Decision Trees ‡∏´‡∏•‡∏≤‡∏¢‡πÜ ‡∏ï‡πâ‡∏ô\n",
    "- ‡πÉ‡∏ä‡πâ bagging (bootstrap aggregating) ‡πÅ‡∏•‡∏∞ random feature selection\n",
    "- ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏Ç‡∏±‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏ß‡∏ï‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á:**\n",
    "- ‡∏•‡∏î overfitting ‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤ Decision Tree ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß\n",
    "- ‡πÉ‡∏´‡πâ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÉ‡∏ô‡∏´‡∏•‡∏≤‡∏¢‡∏õ‡∏±‡∏ç‡∏´‡∏≤\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ noise ‡πÑ‡∏î‡πâ‡∏î‡∏µ\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô:**\n",
    "- ‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ Decision Tree ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß\n",
    "- ‡πÉ‡∏ä‡πâ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤\n",
    "- ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡πÄ‡∏™‡πâ‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f87fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• Random Forest\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "rf_classifier.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
    "y_pred_rf = rf_classifier.predict(X_test_tree)\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "accuracy_rf = accuracy_score(y_test_tree, y_pred_rf)\n",
    "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á Random Forest: {accuracy_rf:.3f}\")\n",
    "\n",
    "# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö Decision Tree\n",
    "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á Decision Tree: {accuracy_tree:.3f}\")\n",
    "print(f\"‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á: {accuracy_rf - accuracy_tree:.3f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Feature Importance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Random Forest\n",
    "rf_feature_importance = rf_classifier.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(len(feature_importance)), feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('Feature Importance - Decision Tree')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(range(len(rf_feature_importance)), rf_feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('Feature Importance - Random Forest')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û\n",
    "dt_scores = cross_val_score(dt_classifier, X_iris, y_iris, cv=5)\n",
    "rf_scores = cross_val_score(rf_classifier, X_iris, y_iris, cv=5)\n",
    "\n",
    "print(f\"\\nCross-validation scores:\")\n",
    "print(f\"Decision Tree: {dt_scores.mean():.3f} ¬± {dt_scores.std():.3f}\")\n",
    "print(f\"Random Forest: {rf_scores.mean():.3f} ¬± {rf_scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d3452f",
   "metadata": {},
   "source": [
    "### 2.3 XGBoost (Extreme Gradient Boosting, ‡∏†‡∏≤‡∏Ñ‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å Decision Tree)\n",
    "\n",
    "**‡∏ó‡∏§‡∏©‡∏é‡∏µ:**\n",
    "- XGBoost ‡πÄ‡∏õ‡πá‡∏ô gradient boosting algorithm ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á\n",
    "- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏Å‡πà‡∏≤\n",
    "- ‡πÉ‡∏ä‡πâ regularization ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô overfitting\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á:**\n",
    "- ‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Ç‡πà‡∏á‡∏Ç‡∏±‡∏ô machine learning\n",
    "- ‡∏°‡∏µ built-in regularization\n",
    "- ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏±‡∏ö missing values ‡πÑ‡∏î‡πâ\n",
    "\n",
    "**‡∏à‡∏∏‡∏î‡∏≠‡πà‡∏≠‡∏ô:**\n",
    "- ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö hyperparameters\n",
    "- ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ù‡∏∂‡∏Å‡∏ô‡∏≤‡∏ô‡∏Å‡∏ß‡πà‡∏≤ Random Forest\n",
    "- ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏•‡∏∂‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd7002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• XGBoost\n",
    "xgb_classifier = xgb.XGBClassifier(max_depth=3, n_estimators=100, eta=0.3)\n",
    "xgb_classifier.fit(X_train_tree, y_train_tree)\n",
    "\n",
    "# ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•\n",
    "y_pred_xgb = xgb_classifier.predict(X_test_tree)\n",
    "\n",
    "# ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥\n",
    "accuracy_xgb = accuracy_score(y_test_tree, y_pred_xgb)\n",
    "print(f\"‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á XGBoost: {accuracy_xgb:.3f}\")\n",
    "\n",
    "# ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏≠‡∏∑‡πà‡∏ô\n",
    "print(\"\\n‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥:\")\n",
    "print(f\"Decision Tree: {accuracy_tree:.3f}\")\n",
    "print(f\"Random Forest: {accuracy_rf:.3f}\")\n",
    "print(f\"XGBoost: {accuracy_xgb:.3f}\")\n",
    "\n",
    "# ‡πÅ‡∏™‡∏î‡∏á Feature Importance ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö XGBoost\n",
    "xgb_feature_importance = xgb_classifier.feature_importances_\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.bar(range(len(feature_importance)), feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('Decision Tree')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.bar(range(len(rf_feature_importance)), rf_feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('Random Forest')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.bar(range(len(xgb_feature_importance)), xgb_feature_importance)\n",
    "plt.xticks(range(len(feature_names)), feature_names, rotation=45)\n",
    "plt.title('XGBoost')\n",
    "plt.ylabel('Importance')\n",
    "\n",
    "plt.suptitle('‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Feature Importance ‡∏Ç‡∏≠‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ï‡πà‡∏≤‡∏á‡πÜ')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cross-validation\n",
    "xgb_scores = cross_val_score(xgb_classifier, X_iris, y_iris, cv=5)\n",
    "print(f\"\\nCross-validation scores:\")\n",
    "print(f\"Decision Tree: {dt_scores.mean():.3f} ¬± {dt_scores.std():.3f}\")\n",
    "print(f\"Random Forest: {rf_scores.mean():.3f} ¬± {rf_scores.std():.3f}\")\n",
    "print(f\"XGBoost: {xgb_scores.mean():.3f} ¬± {xgb_scores.std():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
